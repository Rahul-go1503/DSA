# Selection Sort :
> select/set the min element
> i smallest element par rahta hai
> compare between two loop : swap (arr[i],arr[j]);
> T.C O(N2); S.C O(1);

# Bubble Sort :
> bubble out the max element
> i used only for tracking rounds
> j always on max element and put the max element to the right postion
> compare within same loop - swap(arr[j], arr[j+1]);
> T.C - B.C : O(N) , W.C : O(N2);

# Insertion Sort :
> insert at right position
> no swap

# Merge Sort :
> T.C - O(nLogn) in all 3 cases (worst, average and best) as merge sort always divides the array into two halves and takes linear time to merge two halves.
> Auxiliary Space: O(n)
> Algorithmic Paradigm: Divide and Conquer
> Sorting In Place: No in a typical implementation
> Stable: Yes

# Quick Sort :
> https://www.geeksforgeeks.org/quick-sort/
> partioning positioning
> divide and conquer method , Recursive
> smaller elem < elem < larger elem
> low high , i j , pivot
> T.C - BC - O(NlogN) when list always divide in middle
      - WC - O(N2) when list is always divide in 1st or last post ~ sorted or reverse sorted


# Heap Sort :

---

## Stable and Unstable Sorting Algorithms
> https://www.geeksforgeeks.org/stable-and-unstable-sorting-algorithms/
> Which sorting algorithms are stable?

> Which sorting algorithms are unstable?

> Can we make any sorting algorithm stable?
